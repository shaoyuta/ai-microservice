FROM registry.cn-shanghai.aliyuncs.com/taosy/vllm-xft-base:0.01 AS build
ARG HF_ENDPOINT
ARG HF_TOKEN

# Set the environment variable
ENV HF_TOKEN=$HF_TOKEN
ENV HF_ENDPOINT=$HF_ENDPOINT

# Prepare download model
RUN git config --global credential.helper store
RUN echo /usr/bin/python3.8/bin/huggingface-cli login --token $HF_TOKEN --add-to-git-credential

# Download model
RUN mkdir -p /data/Llama-2-7b-chat-hf
RUN /usr/bin/python3.8/bin/huggingface-cli download --resume-download --local-dir-use-symlinks False  meta-llama/Llama-2-7b-chat-hf --local-dir /data/Llama-2-7b-chat-hf

# Convert model
RUN python -c 'import xfastertransformer as xft; xft.LlamaConvert().convert("/data/Llama-2-7b-chat-hf","/data/Llama-2-7b-chat-hf-xft")'

# Cleanup
RUN mkdir /data/configs  &&  \
    cp /data/Llama-2-7b-chat-hf/*.json /data/configs
RUN rm /root/.cache/huggingface/ /data/Llama-2-7b-chat-hf/ -fr


# Copy files to target image
FROM registry.cn-shanghai.aliyuncs.com/taosy/vllm-xft-base:0.01

COPY --from=build /data /data

ARG port=8000
ENV port=${port}


CMD ( python -m vllm.entrypoints.openai.api_server --model /data/Llama-2-7b-chat-hf-xft/ --port ${port} --tokenizer /data/configs/ --trust-remote-code --xft_dtype "bf16")

